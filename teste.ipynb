{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: torch in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (2.5.1)\n",
      "Collecting peft\n",
      "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from peft) (6.1.0)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leo72\\documents\\teste\\.venv\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "Downloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
      "Installing collected packages: accelerate, peft\n",
      "Successfully installed accelerate-1.1.1 peft-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "/home/guilherme/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:774: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/guilherme/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "MODEL_VERSION = 1\n",
    "\n",
    "base_model_name = \"bert-base-uncased\"\n",
    "adapter_path = f\"./models/model_{MODEL_VERSION}/fine_tuned_lora_mlm\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "base_model = AutoModelForMaskedLM.from_pretrained(base_model_name, output_hidden_states=True)\n",
    "model = PeftModel.from_pretrained(base_model, adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.59184411e-01  1.04749784e-01  4.89766821e-02  1.19697057e-01\n",
      "  4.64422703e-01 -3.61814559e-01  2.74628580e-01  3.36516291e-01\n",
      "  1.00488737e-01 -5.50551116e-01  2.26543695e-01  1.48407355e-01\n",
      "  5.83740994e-02  2.97494531e-01 -3.78306448e-01  4.50280786e-01\n",
      "  8.03930163e-02  2.43607253e-01  1.84037805e-01 -2.21060850e-02\n",
      "  5.97796738e-02 -2.07727894e-01 -1.73781350e-01  2.87904680e-01\n",
      " -4.92344409e-01 -4.28109355e-02  3.28049771e-02 -1.19974285e-01\n",
      " -5.02179027e-01  2.61972636e-01 -1.28775567e-01  1.28682896e-01\n",
      " -2.71517754e-01 -2.17973709e-01 -4.35077846e-01 -3.79266925e-02\n",
      "  2.73012370e-02 -8.87770876e-02 -1.45556986e-01  6.98257014e-02\n",
      " -2.31916815e-01 -2.23698884e-01 -4.42977622e-02  1.62013501e-01\n",
      "  8.07240754e-02  3.35303918e-02 -3.23557884e-01  4.20951471e-03\n",
      "  3.30137610e-01  2.22963184e-01 -3.84423167e-01  3.87669891e-01\n",
      "  4.24453840e-02 -2.50005890e-02  3.79839718e-01  1.48208797e-01\n",
      " -2.00261235e-01 -4.12309647e-01  9.54100676e-03 -1.80492356e-01\n",
      "  3.26197237e-01  2.54425168e-01  3.41032773e-01 -4.61446084e-02\n",
      "  2.43644565e-01  1.12185769e-01 -1.40193745e-01  2.08179250e-01\n",
      " -9.94162410e-02 -3.30290914e-01 -1.58802450e-01  1.89949363e-01\n",
      " -3.00883800e-01  5.97855970e-02 -4.72288132e-02  5.61645851e-02\n",
      " -1.79763585e-01  2.76943982e-01 -9.98882949e-03  4.01630938e-01\n",
      " -6.67051971e-02 -3.45255524e-01  8.83260965e-02  1.39510661e-01\n",
      " -1.51954591e-03  1.79423496e-01  1.30759954e-01  1.60405323e-01\n",
      " -3.44075486e-02  1.46547332e-01 -1.71770100e-02  1.67727828e-01\n",
      " -3.99741232e-02  1.51872009e-01  2.57393986e-01  6.07810140e-01\n",
      "  1.60611197e-01  1.67484865e-01 -4.65154983e-02  1.04018971e-02\n",
      "  1.48459554e-01  8.68687406e-02 -1.06024250e-01 -1.13085352e-01\n",
      " -3.30320805e-01  1.86217874e-01 -3.74557853e-01  1.75345317e-02\n",
      "  1.49465948e-01  2.10098475e-02  2.43831515e-01  1.01652890e-01\n",
      "  1.29201293e-01 -3.48426700e-01 -4.05546546e-01 -6.37254566e-02\n",
      " -3.77809629e-02 -3.16960365e-03  6.60192072e-01 -1.00842297e-01\n",
      "  1.96801350e-01 -1.44876540e-03 -1.28331318e-01  5.01205206e-01\n",
      "  1.94488078e-01  3.82049650e-01 -3.44653219e-01  4.13359217e-02\n",
      " -4.85522859e-02  2.14774907e-01 -3.50562900e-01  2.20726281e-01\n",
      "  3.33935976e-01 -7.99243078e-02 -8.01627278e-01  1.99807480e-01\n",
      "  3.50945443e-02  2.72440612e-01 -1.79368332e-01 -2.38472164e-01\n",
      " -1.82591721e-01  2.82668471e-01 -1.53250635e-01 -2.87315935e-01\n",
      "  4.03481901e-01  2.05318511e-01  5.72325349e-01  2.52644390e-01\n",
      "  2.32976705e-01 -2.77762115e-03  1.17816389e-01  4.01544906e-02\n",
      "  7.71265551e-02 -3.36924255e-01 -1.56266153e-01  1.57213137e-01\n",
      "  3.39069143e-02 -3.28524232e-01 -2.01670274e-01 -2.54380219e-02\n",
      "  2.75114238e-01  1.84500784e-01 -1.84369087e-01  1.22234829e-01\n",
      "  6.40911087e-02 -6.29777536e-02  1.49590507e-01  5.66086918e-02\n",
      "  3.42507660e-01  1.58221990e-01 -1.03566185e-01 -6.43273257e-03\n",
      "  1.69513777e-01 -2.50904679e-01 -2.12600484e-01  2.12251455e-01\n",
      " -1.85265511e-01 -5.16399853e-02  5.26553750e-01  4.30847496e-01\n",
      " -1.13556588e+00  7.77873471e-02 -2.21406788e-01  3.31064641e-01\n",
      " -2.36940682e-02 -1.95937425e-01 -2.13971317e-01 -6.10679612e-02\n",
      "  2.10668504e-01  3.29029053e-01 -6.04525149e-01  2.22986042e-01\n",
      " -2.75286287e-01 -1.75042450e-03  3.90934676e-01 -3.89699638e-01\n",
      " -5.17170608e-01  9.55204740e-02 -8.94330591e-02 -4.23405319e-02\n",
      "  1.69944227e-01 -2.35398740e-01  4.81097609e-01  2.23752111e-01\n",
      " -3.86016130e-01 -6.47346154e-02 -1.86461974e-02 -3.76787335e-02\n",
      " -2.89482713e-01  1.78957358e-03 -5.83139181e-01 -1.80017054e-02\n",
      " -1.24349758e-01 -3.25558335e-01  1.55199379e-01  2.67394125e-01\n",
      "  1.06494017e-01 -2.86478132e-01  2.81780541e-01  8.04905891e-02\n",
      "  2.72815347e-01 -1.97824940e-01 -1.47255182e-01  4.02813852e-01\n",
      " -2.45532796e-01  1.52722344e-01  2.25292832e-01  3.95860612e-01\n",
      "  5.52982688e-01  9.43780541e-02 -2.96561569e-01 -8.73544365e-02\n",
      "  2.88857222e-01 -7.84520656e-02  4.12990190e-02 -1.30847655e-02\n",
      "  9.34644565e-02 -2.18576476e-01 -2.64492184e-01 -2.19836712e-01\n",
      " -2.56161809e-01  3.94371599e-01  3.03308606e-01 -7.28573054e-02\n",
      " -3.02769244e-04 -2.14804515e-01 -3.24171148e-02  5.99937975e-01\n",
      " -1.17930897e-01 -2.33506471e-01 -1.95747331e-01  2.66290188e-01\n",
      "  2.18667209e-01 -4.09814656e-01  8.79448205e-02 -3.19798648e-01\n",
      " -2.43813336e-01 -2.04658266e-02 -2.74956644e-01  1.20864727e-01\n",
      "  1.71481341e-01  1.79988258e-02  3.91129434e-01  6.11852892e-02\n",
      " -2.91436136e-01 -2.67893791e-01  1.59842253e-01  2.80222028e-01\n",
      "  1.74435943e-01  3.99218462e-02 -2.51589008e-02  1.50428414e-01\n",
      " -2.58618087e-01  6.87836260e-02 -2.34354809e-01  2.42289007e-02\n",
      "  8.50063860e-02  1.65811002e-01 -1.36209894e-02 -6.35765120e-02\n",
      "  8.99681002e-02  4.81291041e-02 -7.52066299e-02 -9.25694481e-02\n",
      " -1.13733388e-01 -2.86337823e-01 -1.09147638e-01 -2.18593210e-01\n",
      "  1.45100459e-01  2.49588147e-01  2.49404907e-02 -1.20477453e-02\n",
      "  2.00693518e-01  2.79611021e-01  7.77833462e-01 -9.79542732e-02\n",
      " -7.75464624e-02  3.20590198e-01  2.26572156e-01 -2.35292360e-01\n",
      " -2.22260803e-01  6.10486045e-02  1.09098472e-01 -6.85606338e-03\n",
      " -9.49278921e-02 -2.45930016e-01 -8.69305804e-03 -5.96818849e-02\n",
      " -4.65338326e+00  5.68282306e-02  2.62215823e-01 -4.82331097e-01\n",
      " -2.48712391e-01  2.64731422e-03 -2.44782284e-01 -1.17245853e-01\n",
      " -3.99982274e-01  2.23669127e-01 -1.22304872e-01 -5.50275072e-02\n",
      "  2.18530923e-01  1.51370421e-01 -5.41692078e-02  1.10559285e-01\n",
      " -1.95919022e-01  1.09973669e-01 -2.88788229e-01  4.83986378e-01\n",
      " -4.02975529e-01 -4.21247959e-01  3.54258716e-02  3.36743221e-02\n",
      "  4.45487201e-02 -2.95748413e-01 -3.06855917e-01  3.17947417e-02\n",
      " -1.61575690e-01  1.84885822e-02  4.51962590e-01 -2.25580677e-01\n",
      " -1.55004650e-01  1.17832825e-01 -7.95229524e-02 -1.67025387e-01\n",
      "  7.16493726e-02 -2.19095528e-01 -7.77994692e-02  4.08602469e-02\n",
      "  1.05160475e-02 -1.61332116e-01 -1.89765006e-01  4.37681496e-01\n",
      "  1.31327584e-01  5.74795902e-02  5.73144630e-02  3.27043027e-01\n",
      "  3.78914833e-01  4.18132059e-02 -2.41870657e-01 -4.74839091e-01\n",
      "  6.49227947e-02 -9.47032571e-02  4.86885197e-03  8.36555064e-02\n",
      " -2.61312984e-02  1.61647156e-01 -3.51643801e-01  1.54653102e-01\n",
      " -8.72167572e-03 -3.19876373e-01 -2.94620991e-01 -3.01297963e-01\n",
      " -3.23592842e-01 -8.79075229e-02 -4.68255371e-01 -7.83201307e-02\n",
      "  1.97263524e-01  1.92010462e-01 -9.97524410e-02  4.03820723e-02\n",
      "  1.17250606e-02 -4.97564137e-01 -1.52883425e-01 -2.20704619e-02\n",
      " -2.51500487e-01  1.64430171e-01  2.89613336e-01 -1.05749674e-01\n",
      " -1.59275487e-01  6.76505387e-01  1.92280158e-01 -1.39062196e-01\n",
      "  1.68095216e-01  1.61137730e-01 -2.93965667e-01 -2.33306006e-01\n",
      " -3.84241268e-02 -2.35727847e-01  2.07198575e-01 -2.02435583e-01\n",
      "  3.83746564e-01  1.31705806e-01 -8.33504349e-02  2.59342611e-01\n",
      " -2.08025441e-01  1.29551232e-01  1.47395238e-01  1.80272654e-01\n",
      " -1.08505249e-01 -3.32882881e-01  3.83292258e-01 -3.96163374e-01\n",
      " -3.81453425e-01  2.76004463e-01 -3.45863819e-01  1.20329380e-01\n",
      " -1.79450423e-01 -2.57879585e-01 -2.69577280e-03 -1.49691403e-01\n",
      "  1.36634201e-01 -3.96292090e-01 -9.34304893e-02  2.12538525e-01\n",
      "  1.10042706e-01  6.94129616e-02  1.34312570e-01  5.17864041e-02\n",
      " -2.12455481e-01  2.56293625e-01  7.97261298e-02 -2.63901979e-01\n",
      " -1.30618095e-01  3.21194053e-01  1.95084270e-02  3.38085294e-01\n",
      " -1.10237367e-01  1.27888784e-01 -4.12393436e-02 -9.73128229e-02\n",
      " -1.04457617e-01  2.75271684e-01  2.96899498e-01  6.68966100e-02\n",
      " -7.25704655e-02 -4.68793660e-02  1.91646785e-01  6.83972090e-02\n",
      " -7.18623698e-02  1.17448509e-01 -5.48395738e-02 -4.67682220e-02\n",
      "  2.74170488e-01 -2.40993917e-01 -2.57570595e-02 -3.00398648e-01\n",
      " -1.00850172e-01  2.55320936e-01 -1.18392795e-01 -5.70598915e-02\n",
      " -2.43547875e-02  1.23025492e-01 -1.20576166e-01  2.95477271e-01\n",
      "  3.37387532e-01 -1.41072169e-01 -3.65219623e-01 -2.32930839e-01\n",
      "  8.02898109e-02 -1.79907903e-01 -3.66080612e-01  6.38728663e-02\n",
      " -1.37656659e-01  3.31034362e-02 -1.62630215e-01 -1.61685556e-01\n",
      "  7.76073784e-02  2.87111521e-01 -5.01078725e-01  7.82609284e-02\n",
      " -5.99916354e-02 -8.20359811e-02  3.31051677e-01  2.16153637e-01\n",
      " -2.04812571e-01 -1.57227546e-01  4.10380185e-01  4.67600375e-01\n",
      " -3.09794955e-03 -1.90432623e-01 -4.42217886e-02 -4.23013359e-01\n",
      "  1.14741415e-01 -4.03861851e-01  1.56205267e-01 -1.94012552e-01\n",
      "  4.50997651e-02 -2.90810585e-01 -1.71182349e-01  1.18056521e-01\n",
      "  6.36583567e-02 -2.99051255e-01  1.13170967e-02 -6.12464920e-02\n",
      "  3.20491493e-02 -1.30033389e-01 -4.89656776e-02  1.55792385e-02\n",
      " -1.11212432e-02  2.13991821e-01 -1.47727147e-01 -3.07585835e-01\n",
      " -2.91995555e-01 -2.47587889e-01  2.24781111e-01  1.28990402e-02\n",
      " -2.95363605e-01  9.93875787e-02 -3.76005024e-02 -6.58600807e-01\n",
      " -1.38669506e-01  3.71923983e-01  9.04560089e-04  3.69423404e-02\n",
      "  3.70906651e-01 -1.74535438e-01 -1.08790427e-01  1.14514507e-01\n",
      " -4.78859782e-01 -6.35407642e-02  9.45502296e-02  2.57568121e-01\n",
      " -1.42170548e-01  2.56009102e-02  1.17191404e-01 -1.57477528e-01\n",
      "  4.30618584e-01 -1.47040546e-01 -3.72369260e-01 -1.04777977e-01\n",
      "  1.27447546e-02  3.55050176e-01 -9.52630863e-02 -1.14974871e-01\n",
      "  8.99196416e-02  1.12800956e-01  3.07745367e-01  9.73542556e-02\n",
      " -3.48825157e-01 -2.83945873e-02  1.06468581e-01 -2.48491406e-01\n",
      "  6.08315706e-01  2.24823400e-01  2.97205485e-02  1.28397331e-01\n",
      " -2.36962572e-01 -1.37355864e-01 -2.12501556e-01 -1.15446635e-01\n",
      " -4.62439954e-01  9.76941548e-03  2.27399647e-01 -5.96357048e-01\n",
      " -1.44972116e-01  1.85208023e-03 -4.09410059e-01 -4.89765182e-02\n",
      "  5.45577258e-02 -6.02359883e-02  2.87257791e-01  9.80919302e-02\n",
      "  6.17606007e-02  1.59914404e-01  1.36944398e-01  6.91833794e-02\n",
      "  4.78695482e-01 -4.21350509e-01  5.55497110e-01 -6.39240742e-02\n",
      "  2.47659177e-01  1.63077980e-01  5.71118295e-03  7.54580349e-02\n",
      " -1.28735229e-03 -8.87997448e-03 -6.87273517e-02 -2.89570764e-02\n",
      " -3.21379483e-01 -2.45197222e-01 -7.43623078e-02 -1.38822459e-02\n",
      "  1.25863910e-01  1.39791947e-02 -2.42091313e-01 -1.29931465e-01\n",
      "  6.48238957e-02  5.11622392e-02  3.09161603e-01  7.13278353e-02\n",
      "  3.02850865e-02 -2.99923301e-01  7.20917806e-02 -1.78199515e-01\n",
      " -4.42380488e-01 -2.55987048e-01 -1.68170348e-01  4.34727818e-02\n",
      "  7.65224770e-02  8.11338127e-01  2.62436688e-01  1.16279513e-01\n",
      "  3.89627993e-01  3.93407643e-01 -1.60127178e-01 -3.51926744e-01\n",
      " -8.66280645e-02  1.21235467e-01 -1.00753352e-01 -2.22345412e-01\n",
      " -2.38969326e-02  3.46134424e-01 -1.63611501e-01 -1.97797388e-01\n",
      " -3.02989706e-02  4.31045890e-02 -2.07072675e-01  1.29872747e-02\n",
      " -1.03584349e-01 -1.96113139e-01  3.34361345e-01  8.82484913e-02\n",
      "  2.18082219e-01 -7.50746578e-02  3.33304256e-02 -1.80128396e-01\n",
      "  3.57020080e-01 -1.38102904e-01  3.65288436e-01  2.05259055e-01\n",
      "  4.32228670e-02  7.51405284e-02 -9.80783179e-02 -2.02026710e-01\n",
      "  1.51392259e-02 -4.46780592e-01  7.85894692e-02  4.66128916e-01\n",
      "  1.30372524e-01  2.46618733e-01 -3.88728976e-02  5.89000583e-02\n",
      "  2.82525599e-01  1.92527063e-02 -8.76702145e-02  2.07075134e-01\n",
      " -8.45555589e-02  1.43900160e-02 -5.30599058e-02 -1.63696244e-01\n",
      "  5.19687533e-02  1.31782323e-01 -1.79988682e-01  1.76672623e-01\n",
      "  1.22681513e-01  2.90683448e-01  4.32125032e-01  1.31434053e-01\n",
      " -6.66406751e-03  2.30374068e-01  2.52531826e-01 -2.74585932e-02\n",
      " -2.08578706e-01  1.63998395e-01 -8.22528452e-03 -9.14165080e-02\n",
      " -3.96299176e-02 -1.49234861e-01 -2.54064977e-01  1.16494484e-01\n",
      " -1.65725753e-01  1.33633763e-02  1.99268550e-01  2.62277246e-01\n",
      "  2.00330168e-01 -1.45642236e-02  1.07635081e-01 -6.79849982e-02\n",
      " -1.45337321e-02 -4.05016243e-01 -1.02753699e-01 -1.58336654e-01\n",
      " -1.64995492e-01 -3.26166540e-01 -6.56949431e-02 -1.11205496e-01\n",
      "  2.06054971e-02 -1.94317654e-01 -2.57030874e-01 -1.09421052e-02\n",
      "  4.25807565e-01 -1.52524158e-01  2.63152063e-01  2.08251312e-01\n",
      " -7.58394003e-02 -1.08005464e-01  1.93998128e-01 -1.14520453e-01\n",
      "  3.37339163e-01 -2.94798374e-01 -2.48034313e-01 -1.05834447e-01\n",
      "  2.39968318e-02  1.63878202e-01  2.37763748e-02 -2.36237660e-01\n",
      " -6.18064225e-01 -1.09542035e-01 -2.86083341e-01 -2.50717312e-01\n",
      " -1.21772230e-01  3.25951338e-01 -3.38737339e-01  8.77784640e-02\n",
      "  2.35170335e-01  2.20242403e-02  2.19744310e-01 -2.60127872e-01\n",
      " -1.05938986e-01 -6.36832491e-02  1.59106731e-01 -1.34636253e-01\n",
      " -8.47948790e-02 -3.67394537e-01  3.81889008e-02 -1.10379159e-02\n",
      "  1.42209262e-01  1.20990261e-01  5.51934764e-02  6.76235631e-02\n",
      " -9.86214131e-02  4.91611242e-01 -3.93620580e-01 -3.04533184e-01\n",
      "  1.42366767e-01 -1.14540368e-01  6.23213090e-02 -2.36656055e-01\n",
      " -1.30839422e-02  1.06279530e-01  3.49474490e-01  2.17649445e-01\n",
      " -1.75797850e-01 -2.21054420e-01 -5.01579419e-03 -1.93426996e-01\n",
      "  9.16357189e-02  2.17685103e-01 -1.13668807e-01 -2.91725576e-01\n",
      "  1.65730640e-01 -1.92291826e-01  6.62834048e-02  8.61297771e-02\n",
      " -2.04300433e-02 -3.62333566e-01 -1.85447216e-01  3.17887217e-01]\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o para codificar as entradas usando o modelo LoRA\n",
    "def encoder(inputs):\n",
    "    embeddings = []\n",
    "    for input_text in inputs:\n",
    "        # Tokenizar a entrada\n",
    "        tokens = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "\n",
    "        # Certifique-se de que os tensores estejam na mesma device do modelo\n",
    "        tokens = {key: val for key, val in tokens.items()}\n",
    "\n",
    "        # Passar os tokens pelo modelo (incluindo os adaptadores LoRA)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokens)  # Chamada ao modelo\n",
    "            # Extra√ß√£o do embedding da √∫ltima camada oculta\n",
    "            embedding = outputs.hidden_states[-1].mean(dim=1).squeeze().cpu().numpy()\n",
    "            embeddings.append(embedding)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# Gerar embeddings para uma lista de descri√ß√µes de CVE\n",
    "cve_descriptions = [\"Teste descri√ß√£o\"]\n",
    "embeddings_train = encoder(cve_descriptions)\n",
    "\n",
    "# Verificar o comprimento do embedding gerado\n",
    "print(embeddings_train[0])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
