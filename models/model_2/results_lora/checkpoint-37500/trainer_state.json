{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9968832414289137,
  "eval_steps": 500,
  "global_step": 37500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007991688643810438,
      "grad_norm": 2.732752799987793,
      "learning_rate": 0.0004986680518926982,
      "loss": 3.1368,
      "step": 100
    },
    {
      "epoch": 0.015983377287620875,
      "grad_norm": 3.0292582511901855,
      "learning_rate": 0.0004973361037853965,
      "loss": 3.0099,
      "step": 200
    },
    {
      "epoch": 0.02397506593143131,
      "grad_norm": 2.477691411972046,
      "learning_rate": 0.0004960041556780948,
      "loss": 2.913,
      "step": 300
    },
    {
      "epoch": 0.03196675457524175,
      "grad_norm": 2.91054105758667,
      "learning_rate": 0.0004946722075707931,
      "loss": 2.8346,
      "step": 400
    },
    {
      "epoch": 0.03995844321905218,
      "grad_norm": 2.6438703536987305,
      "learning_rate": 0.0004933535789445644,
      "loss": 2.8479,
      "step": 500
    },
    {
      "epoch": 0.04795013186286262,
      "grad_norm": 3.6584205627441406,
      "learning_rate": 0.0004920216308372626,
      "loss": 2.824,
      "step": 600
    },
    {
      "epoch": 0.05594182050667306,
      "grad_norm": 3.443819999694824,
      "learning_rate": 0.0004906896827299609,
      "loss": 2.7525,
      "step": 700
    },
    {
      "epoch": 0.0639335091504835,
      "grad_norm": 2.6627304553985596,
      "learning_rate": 0.0004893577346226591,
      "loss": 2.7015,
      "step": 800
    },
    {
      "epoch": 0.07192519779429393,
      "grad_norm": 3.3510396480560303,
      "learning_rate": 0.0004880257865153574,
      "loss": 2.7652,
      "step": 900
    },
    {
      "epoch": 0.07991688643810436,
      "grad_norm": 4.011176586151123,
      "learning_rate": 0.00048669383840805567,
      "loss": 2.7167,
      "step": 1000
    },
    {
      "epoch": 0.08790857508191481,
      "grad_norm": 3.67460036277771,
      "learning_rate": 0.0004853752097818269,
      "loss": 2.7044,
      "step": 1100
    },
    {
      "epoch": 0.09590026372572524,
      "grad_norm": 3.060028553009033,
      "learning_rate": 0.0004840432616745252,
      "loss": 2.6518,
      "step": 1200
    },
    {
      "epoch": 0.10389195236953569,
      "grad_norm": 3.384659767150879,
      "learning_rate": 0.00048271131356722344,
      "loss": 2.6444,
      "step": 1300
    },
    {
      "epoch": 0.11188364101334612,
      "grad_norm": 2.9321823120117188,
      "learning_rate": 0.00048137936545992164,
      "loss": 2.6109,
      "step": 1400
    },
    {
      "epoch": 0.11987532965715655,
      "grad_norm": 3.334712028503418,
      "learning_rate": 0.00048004741735261996,
      "loss": 2.6431,
      "step": 1500
    },
    {
      "epoch": 0.127867018300967,
      "grad_norm": 4.30015754699707,
      "learning_rate": 0.0004787154692453182,
      "loss": 2.6271,
      "step": 1600
    },
    {
      "epoch": 0.13585870694477742,
      "grad_norm": 3.081502676010132,
      "learning_rate": 0.0004773835211380165,
      "loss": 2.6,
      "step": 1700
    },
    {
      "epoch": 0.14385039558858786,
      "grad_norm": 4.5047430992126465,
      "learning_rate": 0.00047605157303071474,
      "loss": 2.5667,
      "step": 1800
    },
    {
      "epoch": 0.1518420842323983,
      "grad_norm": 4.265442848205566,
      "learning_rate": 0.00047471962492341295,
      "loss": 2.557,
      "step": 1900
    },
    {
      "epoch": 0.15983377287620873,
      "grad_norm": 3.182345151901245,
      "learning_rate": 0.00047338767681611127,
      "loss": 2.5234,
      "step": 2000
    },
    {
      "epoch": 0.16782546152001918,
      "grad_norm": 3.794981002807617,
      "learning_rate": 0.00047205572870880953,
      "loss": 2.6014,
      "step": 2100
    },
    {
      "epoch": 0.17581715016382962,
      "grad_norm": 4.040923118591309,
      "learning_rate": 0.0004707237806015078,
      "loss": 2.5932,
      "step": 2200
    },
    {
      "epoch": 0.18380883880764007,
      "grad_norm": 3.7622485160827637,
      "learning_rate": 0.00046939183249420605,
      "loss": 2.5705,
      "step": 2300
    },
    {
      "epoch": 0.1918005274514505,
      "grad_norm": 3.5529391765594482,
      "learning_rate": 0.00046805988438690426,
      "loss": 2.641,
      "step": 2400
    },
    {
      "epoch": 0.19979221609526093,
      "grad_norm": 4.0049614906311035,
      "learning_rate": 0.0004667279362796026,
      "loss": 2.5276,
      "step": 2500
    },
    {
      "epoch": 0.20778390473907138,
      "grad_norm": 5.016360282897949,
      "learning_rate": 0.00046539598817230083,
      "loss": 2.5595,
      "step": 2600
    },
    {
      "epoch": 0.2157755933828818,
      "grad_norm": 3.5975420475006104,
      "learning_rate": 0.0004640640400649991,
      "loss": 2.5077,
      "step": 2700
    },
    {
      "epoch": 0.22376728202669224,
      "grad_norm": 4.680834770202637,
      "learning_rate": 0.00046273209195769736,
      "loss": 2.5034,
      "step": 2800
    },
    {
      "epoch": 0.2317589706705027,
      "grad_norm": 4.211978912353516,
      "learning_rate": 0.00046140014385039556,
      "loss": 2.517,
      "step": 2900
    },
    {
      "epoch": 0.2397506593143131,
      "grad_norm": 4.762767791748047,
      "learning_rate": 0.0004600681957430938,
      "loss": 2.4335,
      "step": 3000
    },
    {
      "epoch": 0.24774234795812355,
      "grad_norm": 4.55452823638916,
      "learning_rate": 0.0004587495671168652,
      "loss": 2.506,
      "step": 3100
    },
    {
      "epoch": 0.255734036601934,
      "grad_norm": 2.8916244506835938,
      "learning_rate": 0.0004574176190095634,
      "loss": 2.4612,
      "step": 3200
    },
    {
      "epoch": 0.26372572524574445,
      "grad_norm": 3.6839678287506104,
      "learning_rate": 0.00045608567090226165,
      "loss": 2.4795,
      "step": 3300
    },
    {
      "epoch": 0.27171741388955484,
      "grad_norm": 5.327315330505371,
      "learning_rate": 0.0004547537227949599,
      "loss": 2.4131,
      "step": 3400
    },
    {
      "epoch": 0.2797091025333653,
      "grad_norm": 4.682794094085693,
      "learning_rate": 0.0004534217746876582,
      "loss": 2.3802,
      "step": 3500
    },
    {
      "epoch": 0.28770079117717573,
      "grad_norm": 3.848092794418335,
      "learning_rate": 0.00045208982658035644,
      "loss": 2.4616,
      "step": 3600
    },
    {
      "epoch": 0.2956924798209862,
      "grad_norm": 3.400266408920288,
      "learning_rate": 0.0004507578784730547,
      "loss": 2.3809,
      "step": 3700
    },
    {
      "epoch": 0.3036841684647966,
      "grad_norm": 3.7408628463745117,
      "learning_rate": 0.00044942593036575296,
      "loss": 2.4182,
      "step": 3800
    },
    {
      "epoch": 0.31167585710860707,
      "grad_norm": 3.9559247493743896,
      "learning_rate": 0.0004480939822584512,
      "loss": 2.4423,
      "step": 3900
    },
    {
      "epoch": 0.31966754575241746,
      "grad_norm": 4.129666805267334,
      "learning_rate": 0.0004467620341511495,
      "loss": 2.4419,
      "step": 4000
    },
    {
      "epoch": 0.3276592343962279,
      "grad_norm": 3.9509127140045166,
      "learning_rate": 0.0004454300860438477,
      "loss": 2.4347,
      "step": 4100
    },
    {
      "epoch": 0.33565092304003835,
      "grad_norm": 4.521331787109375,
      "learning_rate": 0.000444098137936546,
      "loss": 2.4499,
      "step": 4200
    },
    {
      "epoch": 0.3436426116838488,
      "grad_norm": 5.256606101989746,
      "learning_rate": 0.00044276618982924427,
      "loss": 2.3858,
      "step": 4300
    },
    {
      "epoch": 0.35163430032765924,
      "grad_norm": 4.335057735443115,
      "learning_rate": 0.0004414342417219425,
      "loss": 2.4251,
      "step": 4400
    },
    {
      "epoch": 0.3596259889714697,
      "grad_norm": 4.796816349029541,
      "learning_rate": 0.0004401022936146408,
      "loss": 2.4496,
      "step": 4500
    },
    {
      "epoch": 0.36761767761528014,
      "grad_norm": 6.099845886230469,
      "learning_rate": 0.000438770345507339,
      "loss": 2.4096,
      "step": 4600
    },
    {
      "epoch": 0.3756093662590905,
      "grad_norm": 3.931281566619873,
      "learning_rate": 0.0004374383974000373,
      "loss": 2.3855,
      "step": 4700
    },
    {
      "epoch": 0.383601054902901,
      "grad_norm": 4.313470363616943,
      "learning_rate": 0.00043610644929273557,
      "loss": 2.4422,
      "step": 4800
    },
    {
      "epoch": 0.3915927435467114,
      "grad_norm": 3.8221967220306396,
      "learning_rate": 0.00043477450118543383,
      "loss": 2.3853,
      "step": 4900
    },
    {
      "epoch": 0.39958443219052187,
      "grad_norm": 3.2951762676239014,
      "learning_rate": 0.0004334425530781321,
      "loss": 2.4277,
      "step": 5000
    },
    {
      "epoch": 0.4075761208343323,
      "grad_norm": 5.738968372344971,
      "learning_rate": 0.0004321106049708303,
      "loss": 2.3528,
      "step": 5100
    },
    {
      "epoch": 0.41556780947814276,
      "grad_norm": 4.706576347351074,
      "learning_rate": 0.0004307919763446016,
      "loss": 2.4265,
      "step": 5200
    },
    {
      "epoch": 0.42355949812195315,
      "grad_norm": 4.961411952972412,
      "learning_rate": 0.0004294600282372999,
      "loss": 2.3637,
      "step": 5300
    },
    {
      "epoch": 0.4315511867657636,
      "grad_norm": 5.286367416381836,
      "learning_rate": 0.00042812808012999813,
      "loss": 2.3317,
      "step": 5400
    },
    {
      "epoch": 0.43954287540957404,
      "grad_norm": 4.200657367706299,
      "learning_rate": 0.0004267961320226964,
      "loss": 2.3795,
      "step": 5500
    },
    {
      "epoch": 0.4475345640533845,
      "grad_norm": 3.640956163406372,
      "learning_rate": 0.00042546418391539465,
      "loss": 2.3933,
      "step": 5600
    },
    {
      "epoch": 0.45552625269719493,
      "grad_norm": 4.000317573547363,
      "learning_rate": 0.0004241322358080929,
      "loss": 2.3452,
      "step": 5700
    },
    {
      "epoch": 0.4635179413410054,
      "grad_norm": 5.197394371032715,
      "learning_rate": 0.00042280028770079123,
      "loss": 2.3669,
      "step": 5800
    },
    {
      "epoch": 0.47150962998481577,
      "grad_norm": 4.535641670227051,
      "learning_rate": 0.00042146833959348943,
      "loss": 2.3845,
      "step": 5900
    },
    {
      "epoch": 0.4795013186286262,
      "grad_norm": 4.961315155029297,
      "learning_rate": 0.0004201363914861877,
      "loss": 2.3195,
      "step": 6000
    },
    {
      "epoch": 0.48749300727243666,
      "grad_norm": 5.2347025871276855,
      "learning_rate": 0.00041880444337888596,
      "loss": 2.3505,
      "step": 6100
    },
    {
      "epoch": 0.4954846959162471,
      "grad_norm": 5.447612285614014,
      "learning_rate": 0.0004174724952715842,
      "loss": 2.4117,
      "step": 6200
    },
    {
      "epoch": 0.5034763845600575,
      "grad_norm": 3.6135759353637695,
      "learning_rate": 0.00041614054716428253,
      "loss": 2.411,
      "step": 6300
    },
    {
      "epoch": 0.511468073203868,
      "grad_norm": 6.219202518463135,
      "learning_rate": 0.00041480859905698074,
      "loss": 2.4295,
      "step": 6400
    },
    {
      "epoch": 0.5194597618476784,
      "grad_norm": 4.610805988311768,
      "learning_rate": 0.000413476650949679,
      "loss": 2.4159,
      "step": 6500
    },
    {
      "epoch": 0.5274514504914889,
      "grad_norm": 4.918600082397461,
      "learning_rate": 0.00041214470284237726,
      "loss": 2.3433,
      "step": 6600
    },
    {
      "epoch": 0.5354431391352993,
      "grad_norm": 4.779319763183594,
      "learning_rate": 0.0004108127547350755,
      "loss": 2.3272,
      "step": 6700
    },
    {
      "epoch": 0.5434348277791097,
      "grad_norm": 4.660211563110352,
      "learning_rate": 0.00040948080662777384,
      "loss": 2.3283,
      "step": 6800
    },
    {
      "epoch": 0.5514265164229202,
      "grad_norm": 4.773199081420898,
      "learning_rate": 0.00040814885852047205,
      "loss": 2.4031,
      "step": 6900
    },
    {
      "epoch": 0.5594182050667306,
      "grad_norm": 3.485262155532837,
      "learning_rate": 0.00040683022989424335,
      "loss": 2.3578,
      "step": 7000
    },
    {
      "epoch": 0.5674098937105411,
      "grad_norm": 4.750330448150635,
      "learning_rate": 0.0004054982817869416,
      "loss": 2.3414,
      "step": 7100
    },
    {
      "epoch": 0.5754015823543515,
      "grad_norm": 4.7572808265686035,
      "learning_rate": 0.0004041663336796398,
      "loss": 2.3475,
      "step": 7200
    },
    {
      "epoch": 0.583393270998162,
      "grad_norm": 4.459456920623779,
      "learning_rate": 0.0004028343855723381,
      "loss": 2.3291,
      "step": 7300
    },
    {
      "epoch": 0.5913849596419724,
      "grad_norm": 4.769024848937988,
      "learning_rate": 0.0004015024374650364,
      "loss": 2.3468,
      "step": 7400
    },
    {
      "epoch": 0.5993766482857827,
      "grad_norm": 3.7228522300720215,
      "learning_rate": 0.00040017048935773466,
      "loss": 2.3375,
      "step": 7500
    },
    {
      "epoch": 0.6073683369295932,
      "grad_norm": 5.353236198425293,
      "learning_rate": 0.0003988385412504329,
      "loss": 2.314,
      "step": 7600
    },
    {
      "epoch": 0.6153600255734036,
      "grad_norm": 5.861856937408447,
      "learning_rate": 0.0003975065931431311,
      "loss": 2.3749,
      "step": 7700
    },
    {
      "epoch": 0.6233517142172141,
      "grad_norm": 6.393261909484863,
      "learning_rate": 0.0003961746450358294,
      "loss": 2.319,
      "step": 7800
    },
    {
      "epoch": 0.6313434028610245,
      "grad_norm": 5.450260639190674,
      "learning_rate": 0.0003948426969285277,
      "loss": 2.3288,
      "step": 7900
    },
    {
      "epoch": 0.6393350915048349,
      "grad_norm": 5.707064628601074,
      "learning_rate": 0.00039351074882122597,
      "loss": 2.3388,
      "step": 8000
    },
    {
      "epoch": 0.6473267801486454,
      "grad_norm": 4.342197895050049,
      "learning_rate": 0.0003921788007139242,
      "loss": 2.3088,
      "step": 8100
    },
    {
      "epoch": 0.6553184687924558,
      "grad_norm": 5.315873622894287,
      "learning_rate": 0.00039084685260662243,
      "loss": 2.3102,
      "step": 8200
    },
    {
      "epoch": 0.6633101574362663,
      "grad_norm": 4.705062389373779,
      "learning_rate": 0.0003895149044993207,
      "loss": 2.3965,
      "step": 8300
    },
    {
      "epoch": 0.6713018460800767,
      "grad_norm": 3.8893792629241943,
      "learning_rate": 0.00038818295639201896,
      "loss": 2.3335,
      "step": 8400
    },
    {
      "epoch": 0.6792935347238872,
      "grad_norm": 3.87214732170105,
      "learning_rate": 0.00038685100828471727,
      "loss": 2.3278,
      "step": 8500
    },
    {
      "epoch": 0.6872852233676976,
      "grad_norm": 4.7409772872924805,
      "learning_rate": 0.0003855190601774155,
      "loss": 2.3199,
      "step": 8600
    },
    {
      "epoch": 0.695276912011508,
      "grad_norm": 3.800950050354004,
      "learning_rate": 0.00038418711207011374,
      "loss": 2.3543,
      "step": 8700
    },
    {
      "epoch": 0.7032686006553185,
      "grad_norm": 4.960910797119141,
      "learning_rate": 0.000382855163962812,
      "loss": 2.2952,
      "step": 8800
    },
    {
      "epoch": 0.7112602892991289,
      "grad_norm": 4.0987372398376465,
      "learning_rate": 0.00038152321585551026,
      "loss": 2.2939,
      "step": 8900
    },
    {
      "epoch": 0.7192519779429394,
      "grad_norm": 5.018887519836426,
      "learning_rate": 0.0003801912677482086,
      "loss": 2.3313,
      "step": 9000
    },
    {
      "epoch": 0.7272436665867498,
      "grad_norm": 4.482113361358643,
      "learning_rate": 0.0003788593196409068,
      "loss": 2.3243,
      "step": 9100
    },
    {
      "epoch": 0.7352353552305603,
      "grad_norm": 5.078419208526611,
      "learning_rate": 0.00037752737153360505,
      "loss": 2.3142,
      "step": 9200
    },
    {
      "epoch": 0.7432270438743707,
      "grad_norm": 4.784209251403809,
      "learning_rate": 0.0003761954234263033,
      "loss": 2.3022,
      "step": 9300
    },
    {
      "epoch": 0.751218732518181,
      "grad_norm": 5.493999004364014,
      "learning_rate": 0.00037486347531900157,
      "loss": 2.3096,
      "step": 9400
    },
    {
      "epoch": 0.7592104211619916,
      "grad_norm": 4.876006126403809,
      "learning_rate": 0.0003735315272116999,
      "loss": 2.3551,
      "step": 9500
    },
    {
      "epoch": 0.767202109805802,
      "grad_norm": 4.721347332000732,
      "learning_rate": 0.0003721995791043981,
      "loss": 2.3926,
      "step": 9600
    },
    {
      "epoch": 0.7751937984496124,
      "grad_norm": 4.954073905944824,
      "learning_rate": 0.00037086763099709636,
      "loss": 2.3725,
      "step": 9700
    },
    {
      "epoch": 0.7831854870934228,
      "grad_norm": 3.975302219390869,
      "learning_rate": 0.0003695356828897946,
      "loss": 2.3215,
      "step": 9800
    },
    {
      "epoch": 0.7911771757372332,
      "grad_norm": 3.6432676315307617,
      "learning_rate": 0.0003682037347824929,
      "loss": 2.3096,
      "step": 9900
    },
    {
      "epoch": 0.7991688643810437,
      "grad_norm": 6.298996448516846,
      "learning_rate": 0.00036687178667519114,
      "loss": 2.3162,
      "step": 10000
    },
    {
      "epoch": 0.8071605530248541,
      "grad_norm": 5.0301833152771,
      "learning_rate": 0.0003655398385678894,
      "loss": 2.2986,
      "step": 10100
    },
    {
      "epoch": 0.8151522416686646,
      "grad_norm": 5.237517833709717,
      "learning_rate": 0.00036420789046058766,
      "loss": 2.3633,
      "step": 10200
    },
    {
      "epoch": 0.823143930312475,
      "grad_norm": 4.81888484954834,
      "learning_rate": 0.0003628759423532859,
      "loss": 2.3416,
      "step": 10300
    },
    {
      "epoch": 0.8311356189562855,
      "grad_norm": 5.261603355407715,
      "learning_rate": 0.0003615439942459842,
      "loss": 2.3375,
      "step": 10400
    },
    {
      "epoch": 0.8391273076000959,
      "grad_norm": 4.711301803588867,
      "learning_rate": 0.00036022536561975543,
      "loss": 2.2479,
      "step": 10500
    },
    {
      "epoch": 0.8471189962439063,
      "grad_norm": 5.076519966125488,
      "learning_rate": 0.00035889341751245375,
      "loss": 2.2852,
      "step": 10600
    },
    {
      "epoch": 0.8551106848877168,
      "grad_norm": 4.715648651123047,
      "learning_rate": 0.000357561469405152,
      "loss": 2.3074,
      "step": 10700
    },
    {
      "epoch": 0.8631023735315272,
      "grad_norm": 5.4985246658325195,
      "learning_rate": 0.00035622952129785027,
      "loss": 2.3361,
      "step": 10800
    },
    {
      "epoch": 0.8710940621753377,
      "grad_norm": 6.3859543800354,
      "learning_rate": 0.0003548975731905485,
      "loss": 2.2468,
      "step": 10900
    },
    {
      "epoch": 0.8790857508191481,
      "grad_norm": 5.418402671813965,
      "learning_rate": 0.00035356562508324674,
      "loss": 2.3444,
      "step": 11000
    },
    {
      "epoch": 0.8870774394629585,
      "grad_norm": 4.093523025512695,
      "learning_rate": 0.00035223367697594506,
      "loss": 2.3161,
      "step": 11100
    },
    {
      "epoch": 0.895069128106769,
      "grad_norm": 5.629938125610352,
      "learning_rate": 0.0003509017288686433,
      "loss": 2.324,
      "step": 11200
    },
    {
      "epoch": 0.9030608167505794,
      "grad_norm": 5.725546360015869,
      "learning_rate": 0.0003495697807613415,
      "loss": 2.3301,
      "step": 11300
    },
    {
      "epoch": 0.9110525053943899,
      "grad_norm": 6.677602767944336,
      "learning_rate": 0.0003482378326540398,
      "loss": 2.2807,
      "step": 11400
    },
    {
      "epoch": 0.9190441940382003,
      "grad_norm": 4.594287872314453,
      "learning_rate": 0.00034690588454673805,
      "loss": 2.2495,
      "step": 11500
    },
    {
      "epoch": 0.9270358826820108,
      "grad_norm": 5.605828285217285,
      "learning_rate": 0.00034557393643943636,
      "loss": 2.3088,
      "step": 11600
    },
    {
      "epoch": 0.9350275713258211,
      "grad_norm": 4.0877366065979,
      "learning_rate": 0.0003442419883321346,
      "loss": 2.3083,
      "step": 11700
    },
    {
      "epoch": 0.9430192599696315,
      "grad_norm": 5.1784491539001465,
      "learning_rate": 0.00034291004022483283,
      "loss": 2.2776,
      "step": 11800
    },
    {
      "epoch": 0.951010948613442,
      "grad_norm": 6.817361354827881,
      "learning_rate": 0.0003415780921175311,
      "loss": 2.2658,
      "step": 11900
    },
    {
      "epoch": 0.9590026372572524,
      "grad_norm": 5.998700141906738,
      "learning_rate": 0.00034024614401022935,
      "loss": 2.3722,
      "step": 12000
    },
    {
      "epoch": 0.9669943259010629,
      "grad_norm": 7.395671844482422,
      "learning_rate": 0.0003389141959029276,
      "loss": 2.2756,
      "step": 12100
    },
    {
      "epoch": 0.9749860145448733,
      "grad_norm": 5.043878078460693,
      "learning_rate": 0.00033758224779562593,
      "loss": 2.2747,
      "step": 12200
    },
    {
      "epoch": 0.9829777031886837,
      "grad_norm": 4.592922687530518,
      "learning_rate": 0.00033625029968832414,
      "loss": 2.2759,
      "step": 12300
    },
    {
      "epoch": 0.9909693918324942,
      "grad_norm": 5.046980857849121,
      "learning_rate": 0.0003349183515810224,
      "loss": 2.2255,
      "step": 12400
    },
    {
      "epoch": 0.9989610804763046,
      "grad_norm": 5.68693208694458,
      "learning_rate": 0.00033358640347372066,
      "loss": 2.2347,
      "step": 12500
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.0636942386627197,
      "eval_runtime": 186.7836,
      "eval_samples_per_second": 267.962,
      "eval_steps_per_second": 16.752,
      "step": 12513
    },
    {
      "epoch": 1.006952769120115,
      "grad_norm": 4.779221534729004,
      "learning_rate": 0.0003322544553664189,
      "loss": 2.2443,
      "step": 12600
    },
    {
      "epoch": 1.0149444577639255,
      "grad_norm": 5.842565536499023,
      "learning_rate": 0.0003309225072591172,
      "loss": 2.3147,
      "step": 12700
    },
    {
      "epoch": 1.022936146407736,
      "grad_norm": 5.922913074493408,
      "learning_rate": 0.00032959055915181545,
      "loss": 2.2626,
      "step": 12800
    },
    {
      "epoch": 1.0309278350515463,
      "grad_norm": 4.585598945617676,
      "learning_rate": 0.0003282586110445137,
      "loss": 2.237,
      "step": 12900
    },
    {
      "epoch": 1.0389195236953568,
      "grad_norm": 6.996572017669678,
      "learning_rate": 0.00032692666293721197,
      "loss": 2.3169,
      "step": 13000
    },
    {
      "epoch": 1.0469112123391673,
      "grad_norm": 5.235696315765381,
      "learning_rate": 0.00032559471482991023,
      "loss": 2.2411,
      "step": 13100
    },
    {
      "epoch": 1.0549029009829778,
      "grad_norm": 4.901758193969727,
      "learning_rate": 0.0003242627667226085,
      "loss": 2.3266,
      "step": 13200
    },
    {
      "epoch": 1.062894589626788,
      "grad_norm": 5.304924964904785,
      "learning_rate": 0.00032293081861530675,
      "loss": 2.2313,
      "step": 13300
    },
    {
      "epoch": 1.0708862782705986,
      "grad_norm": 5.6912431716918945,
      "learning_rate": 0.000321598870508005,
      "loss": 2.2944,
      "step": 13400
    },
    {
      "epoch": 1.078877966914409,
      "grad_norm": 6.645760536193848,
      "learning_rate": 0.0003202669224007033,
      "loss": 2.2196,
      "step": 13500
    },
    {
      "epoch": 1.0868696555582193,
      "grad_norm": 4.870731353759766,
      "learning_rate": 0.00031893497429340154,
      "loss": 2.2669,
      "step": 13600
    },
    {
      "epoch": 1.0948613442020299,
      "grad_norm": 4.814261436462402,
      "learning_rate": 0.0003176030261860998,
      "loss": 2.3075,
      "step": 13700
    },
    {
      "epoch": 1.1028530328458404,
      "grad_norm": 4.544769763946533,
      "learning_rate": 0.00031627107807879806,
      "loss": 2.2819,
      "step": 13800
    },
    {
      "epoch": 1.1108447214896509,
      "grad_norm": 5.12971305847168,
      "learning_rate": 0.0003149391299714963,
      "loss": 2.2703,
      "step": 13900
    },
    {
      "epoch": 1.1188364101334611,
      "grad_norm": 5.78225040435791,
      "learning_rate": 0.0003136071818641946,
      "loss": 2.2457,
      "step": 14000
    },
    {
      "epoch": 1.1268280987772716,
      "grad_norm": 4.938091278076172,
      "learning_rate": 0.00031227523375689284,
      "loss": 2.2951,
      "step": 14100
    },
    {
      "epoch": 1.1348197874210821,
      "grad_norm": 5.266896724700928,
      "learning_rate": 0.0003109432856495911,
      "loss": 2.2772,
      "step": 14200
    },
    {
      "epoch": 1.1428114760648924,
      "grad_norm": 6.570862770080566,
      "learning_rate": 0.00030961133754228937,
      "loss": 2.1996,
      "step": 14300
    },
    {
      "epoch": 1.150803164708703,
      "grad_norm": 6.207876682281494,
      "learning_rate": 0.00030827938943498763,
      "loss": 2.2729,
      "step": 14400
    },
    {
      "epoch": 1.1587948533525134,
      "grad_norm": 5.716145038604736,
      "learning_rate": 0.0003069607608087589,
      "loss": 2.2951,
      "step": 14500
    },
    {
      "epoch": 1.166786541996324,
      "grad_norm": 6.436923503875732,
      "learning_rate": 0.00030562881270145714,
      "loss": 2.2283,
      "step": 14600
    },
    {
      "epoch": 1.1747782306401342,
      "grad_norm": 5.265610694885254,
      "learning_rate": 0.0003042968645941554,
      "loss": 2.2348,
      "step": 14700
    },
    {
      "epoch": 1.1827699192839447,
      "grad_norm": 7.5213494300842285,
      "learning_rate": 0.0003029649164868537,
      "loss": 2.2802,
      "step": 14800
    },
    {
      "epoch": 1.1907616079277552,
      "grad_norm": 5.450938701629639,
      "learning_rate": 0.000301632968379552,
      "loss": 2.2826,
      "step": 14900
    },
    {
      "epoch": 1.1987532965715655,
      "grad_norm": 5.82449197769165,
      "learning_rate": 0.0003003010202722502,
      "loss": 2.2384,
      "step": 15000
    },
    {
      "epoch": 1.206744985215376,
      "grad_norm": 5.820165157318115,
      "learning_rate": 0.00029896907216494845,
      "loss": 2.2815,
      "step": 15100
    },
    {
      "epoch": 1.2147366738591865,
      "grad_norm": 6.248181343078613,
      "learning_rate": 0.0002976371240576467,
      "loss": 2.2069,
      "step": 15200
    },
    {
      "epoch": 1.222728362502997,
      "grad_norm": 5.161111831665039,
      "learning_rate": 0.000296305175950345,
      "loss": 2.2347,
      "step": 15300
    },
    {
      "epoch": 1.2307200511468073,
      "grad_norm": 5.8171257972717285,
      "learning_rate": 0.0002949732278430433,
      "loss": 2.1803,
      "step": 15400
    },
    {
      "epoch": 1.2387117397906178,
      "grad_norm": 6.546154022216797,
      "learning_rate": 0.0002936412797357415,
      "loss": 2.2664,
      "step": 15500
    },
    {
      "epoch": 1.2467034284344283,
      "grad_norm": 5.926713466644287,
      "learning_rate": 0.00029230933162843975,
      "loss": 2.234,
      "step": 15600
    },
    {
      "epoch": 1.2546951170782386,
      "grad_norm": 6.684126853942871,
      "learning_rate": 0.000290977383521138,
      "loss": 2.2504,
      "step": 15700
    },
    {
      "epoch": 1.262686805722049,
      "grad_norm": 4.931268692016602,
      "learning_rate": 0.0002896454354138363,
      "loss": 2.2797,
      "step": 15800
    },
    {
      "epoch": 1.2706784943658596,
      "grad_norm": 5.9488325119018555,
      "learning_rate": 0.00028831348730653454,
      "loss": 2.28,
      "step": 15900
    },
    {
      "epoch": 1.27867018300967,
      "grad_norm": 4.634033679962158,
      "learning_rate": 0.0002869815391992328,
      "loss": 2.2658,
      "step": 16000
    },
    {
      "epoch": 1.2866618716534803,
      "grad_norm": 6.345796585083008,
      "learning_rate": 0.00028564959109193106,
      "loss": 2.3017,
      "step": 16100
    },
    {
      "epoch": 1.2946535602972908,
      "grad_norm": 4.481930255889893,
      "learning_rate": 0.00028433096246570236,
      "loss": 2.2182,
      "step": 16200
    },
    {
      "epoch": 1.3026452489411011,
      "grad_norm": 4.936617851257324,
      "learning_rate": 0.00028299901435840057,
      "loss": 2.2627,
      "step": 16300
    },
    {
      "epoch": 1.3106369375849116,
      "grad_norm": 4.455478191375732,
      "learning_rate": 0.00028166706625109883,
      "loss": 2.3256,
      "step": 16400
    },
    {
      "epoch": 1.3186286262287221,
      "grad_norm": 4.273805141448975,
      "learning_rate": 0.00028033511814379715,
      "loss": 2.215,
      "step": 16500
    },
    {
      "epoch": 1.3266203148725326,
      "grad_norm": 5.50758171081543,
      "learning_rate": 0.0002790031700364954,
      "loss": 2.2317,
      "step": 16600
    },
    {
      "epoch": 1.3346120035163431,
      "grad_norm": 6.018428802490234,
      "learning_rate": 0.0002776712219291936,
      "loss": 2.2253,
      "step": 16700
    },
    {
      "epoch": 1.3426036921601534,
      "grad_norm": 3.7782230377197266,
      "learning_rate": 0.0002763392738218919,
      "loss": 2.2691,
      "step": 16800
    },
    {
      "epoch": 1.350595380803964,
      "grad_norm": 5.367452621459961,
      "learning_rate": 0.00027500732571459014,
      "loss": 2.2057,
      "step": 16900
    },
    {
      "epoch": 1.3585870694477742,
      "grad_norm": 5.080740928649902,
      "learning_rate": 0.00027367537760728845,
      "loss": 2.2353,
      "step": 17000
    },
    {
      "epoch": 1.3665787580915847,
      "grad_norm": 5.760361671447754,
      "learning_rate": 0.0002723434294999867,
      "loss": 2.2196,
      "step": 17100
    },
    {
      "epoch": 1.3745704467353952,
      "grad_norm": 5.206796169281006,
      "learning_rate": 0.0002710114813926849,
      "loss": 2.2555,
      "step": 17200
    },
    {
      "epoch": 1.3825621353792057,
      "grad_norm": 5.586594104766846,
      "learning_rate": 0.0002696795332853832,
      "loss": 2.2212,
      "step": 17300
    },
    {
      "epoch": 1.3905538240230162,
      "grad_norm": 6.159029960632324,
      "learning_rate": 0.00026834758517808144,
      "loss": 2.2222,
      "step": 17400
    },
    {
      "epoch": 1.3985455126668265,
      "grad_norm": 4.550049781799316,
      "learning_rate": 0.00026701563707077976,
      "loss": 2.2023,
      "step": 17500
    },
    {
      "epoch": 1.406537201310637,
      "grad_norm": 5.4454827308654785,
      "learning_rate": 0.000265683688963478,
      "loss": 2.1845,
      "step": 17600
    },
    {
      "epoch": 1.4145288899544473,
      "grad_norm": 5.098746299743652,
      "learning_rate": 0.00026435174085617623,
      "loss": 2.2547,
      "step": 17700
    },
    {
      "epoch": 1.4225205785982578,
      "grad_norm": 6.1747050285339355,
      "learning_rate": 0.0002630197927488745,
      "loss": 2.255,
      "step": 17800
    },
    {
      "epoch": 1.4305122672420683,
      "grad_norm": 5.415824890136719,
      "learning_rate": 0.00026168784464157275,
      "loss": 2.2361,
      "step": 17900
    },
    {
      "epoch": 1.4385039558858788,
      "grad_norm": 3.733720302581787,
      "learning_rate": 0.00026035589653427107,
      "loss": 2.2726,
      "step": 18000
    },
    {
      "epoch": 1.4464956445296893,
      "grad_norm": 4.520310401916504,
      "learning_rate": 0.00025902394842696933,
      "loss": 2.2331,
      "step": 18100
    },
    {
      "epoch": 1.4544873331734995,
      "grad_norm": 5.1253767013549805,
      "learning_rate": 0.0002577053198007406,
      "loss": 2.1593,
      "step": 18200
    },
    {
      "epoch": 1.46247902181731,
      "grad_norm": 4.774387836456299,
      "learning_rate": 0.00025637337169343884,
      "loss": 2.2378,
      "step": 18300
    },
    {
      "epoch": 1.4704707104611203,
      "grad_norm": 5.041096210479736,
      "learning_rate": 0.0002550414235861371,
      "loss": 2.2337,
      "step": 18400
    },
    {
      "epoch": 1.4784623991049308,
      "grad_norm": 5.8191399574279785,
      "learning_rate": 0.0002537094754788353,
      "loss": 2.2119,
      "step": 18500
    },
    {
      "epoch": 1.4864540877487413,
      "grad_norm": 6.050417423248291,
      "learning_rate": 0.0002523775273715336,
      "loss": 2.2514,
      "step": 18600
    },
    {
      "epoch": 1.4944457763925518,
      "grad_norm": 5.295169353485107,
      "learning_rate": 0.0002510455792642319,
      "loss": 2.2081,
      "step": 18700
    },
    {
      "epoch": 1.5024374650363623,
      "grad_norm": 6.738333225250244,
      "learning_rate": 0.00024971363115693015,
      "loss": 2.2283,
      "step": 18800
    },
    {
      "epoch": 1.5104291536801726,
      "grad_norm": 6.420480251312256,
      "learning_rate": 0.0002483816830496284,
      "loss": 2.3151,
      "step": 18900
    },
    {
      "epoch": 1.518420842323983,
      "grad_norm": 4.657458782196045,
      "learning_rate": 0.00024704973494232667,
      "loss": 2.2496,
      "step": 19000
    },
    {
      "epoch": 1.5264125309677934,
      "grad_norm": 3.931138277053833,
      "learning_rate": 0.00024571778683502493,
      "loss": 2.2575,
      "step": 19100
    },
    {
      "epoch": 1.534404219611604,
      "grad_norm": 5.611766338348389,
      "learning_rate": 0.0002443858387277232,
      "loss": 2.1985,
      "step": 19200
    },
    {
      "epoch": 1.5423959082554144,
      "grad_norm": 6.413047790527344,
      "learning_rate": 0.00024305389062042143,
      "loss": 2.1829,
      "step": 19300
    },
    {
      "epoch": 1.550387596899225,
      "grad_norm": 4.617260932922363,
      "learning_rate": 0.0002417219425131197,
      "loss": 2.2615,
      "step": 19400
    },
    {
      "epoch": 1.5583792855430354,
      "grad_norm": 7.036892890930176,
      "learning_rate": 0.00024038999440581798,
      "loss": 2.3556,
      "step": 19500
    },
    {
      "epoch": 1.5663709741868457,
      "grad_norm": 5.318265438079834,
      "learning_rate": 0.0002390580462985162,
      "loss": 2.1612,
      "step": 19600
    },
    {
      "epoch": 1.574362662830656,
      "grad_norm": 5.997229099273682,
      "learning_rate": 0.00023772609819121447,
      "loss": 2.3129,
      "step": 19700
    },
    {
      "epoch": 1.5823543514744665,
      "grad_norm": 5.282750606536865,
      "learning_rate": 0.00023639415008391273,
      "loss": 2.2178,
      "step": 19800
    },
    {
      "epoch": 1.590346040118277,
      "grad_norm": 8.798601150512695,
      "learning_rate": 0.000235062201976611,
      "loss": 2.1993,
      "step": 19900
    },
    {
      "epoch": 1.5983377287620875,
      "grad_norm": 6.331231117248535,
      "learning_rate": 0.00023373025386930926,
      "loss": 2.2089,
      "step": 20000
    },
    {
      "epoch": 1.606329417405898,
      "grad_norm": 5.399386405944824,
      "learning_rate": 0.00023239830576200752,
      "loss": 2.1614,
      "step": 20100
    },
    {
      "epoch": 1.6143211060497085,
      "grad_norm": 5.904013633728027,
      "learning_rate": 0.00023106635765470578,
      "loss": 2.2108,
      "step": 20200
    },
    {
      "epoch": 1.6223127946935187,
      "grad_norm": 5.253742694854736,
      "learning_rate": 0.00022973440954740404,
      "loss": 2.2845,
      "step": 20300
    },
    {
      "epoch": 1.630304483337329,
      "grad_norm": 4.773291110992432,
      "learning_rate": 0.0002284024614401023,
      "loss": 2.2255,
      "step": 20400
    },
    {
      "epoch": 1.6382961719811395,
      "grad_norm": 5.2915849685668945,
      "learning_rate": 0.00022707051333280056,
      "loss": 2.196,
      "step": 20500
    },
    {
      "epoch": 1.64628786062495,
      "grad_norm": 5.677837371826172,
      "learning_rate": 0.00022573856522549882,
      "loss": 2.2366,
      "step": 20600
    },
    {
      "epoch": 1.6542795492687605,
      "grad_norm": 5.146585941314697,
      "learning_rate": 0.00022440661711819706,
      "loss": 2.216,
      "step": 20700
    },
    {
      "epoch": 1.662271237912571,
      "grad_norm": 4.781584739685059,
      "learning_rate": 0.00022307466901089535,
      "loss": 2.2499,
      "step": 20800
    },
    {
      "epoch": 1.6702629265563813,
      "grad_norm": 6.8456196784973145,
      "learning_rate": 0.0002217427209035936,
      "loss": 2.2485,
      "step": 20900
    },
    {
      "epoch": 1.6782546152001918,
      "grad_norm": 5.522871971130371,
      "learning_rate": 0.00022041077279629184,
      "loss": 2.2303,
      "step": 21000
    },
    {
      "epoch": 1.686246303844002,
      "grad_norm": 5.538457870483398,
      "learning_rate": 0.00021907882468899013,
      "loss": 2.1798,
      "step": 21100
    },
    {
      "epoch": 1.6942379924878126,
      "grad_norm": 4.685487270355225,
      "learning_rate": 0.00021774687658168837,
      "loss": 2.1993,
      "step": 21200
    },
    {
      "epoch": 1.702229681131623,
      "grad_norm": 5.569851875305176,
      "learning_rate": 0.00021641492847438665,
      "loss": 2.2295,
      "step": 21300
    },
    {
      "epoch": 1.7102213697754336,
      "grad_norm": 4.746661186218262,
      "learning_rate": 0.00021508298036708492,
      "loss": 2.2165,
      "step": 21400
    },
    {
      "epoch": 1.718213058419244,
      "grad_norm": 4.769225120544434,
      "learning_rate": 0.00021375103225978315,
      "loss": 2.1382,
      "step": 21500
    },
    {
      "epoch": 1.7262047470630544,
      "grad_norm": 5.539544582366943,
      "learning_rate": 0.00021241908415248144,
      "loss": 2.1635,
      "step": 21600
    },
    {
      "epoch": 1.7341964357068649,
      "grad_norm": 7.298468589782715,
      "learning_rate": 0.00021108713604517967,
      "loss": 2.253,
      "step": 21700
    },
    {
      "epoch": 1.7421881243506752,
      "grad_norm": 5.649975776672363,
      "learning_rate": 0.00020975518793787796,
      "loss": 2.1882,
      "step": 21800
    },
    {
      "epoch": 1.7501798129944857,
      "grad_norm": 5.102168083190918,
      "learning_rate": 0.0002084232398305762,
      "loss": 2.2105,
      "step": 21900
    },
    {
      "epoch": 1.7581715016382962,
      "grad_norm": 5.812136173248291,
      "learning_rate": 0.00020709129172327446,
      "loss": 2.2406,
      "step": 22000
    },
    {
      "epoch": 1.7661631902821067,
      "grad_norm": 6.642938137054443,
      "learning_rate": 0.00020575934361597275,
      "loss": 2.1581,
      "step": 22100
    },
    {
      "epoch": 1.7741548789259172,
      "grad_norm": 4.919799327850342,
      "learning_rate": 0.00020444071498974402,
      "loss": 2.2045,
      "step": 22200
    },
    {
      "epoch": 1.7821465675697274,
      "grad_norm": 4.826469421386719,
      "learning_rate": 0.00020310876688244225,
      "loss": 2.1907,
      "step": 22300
    },
    {
      "epoch": 1.790138256213538,
      "grad_norm": 5.038005352020264,
      "learning_rate": 0.00020177681877514054,
      "loss": 2.237,
      "step": 22400
    },
    {
      "epoch": 1.7981299448573482,
      "grad_norm": 5.117117404937744,
      "learning_rate": 0.00020044487066783878,
      "loss": 2.2377,
      "step": 22500
    },
    {
      "epoch": 1.8061216335011587,
      "grad_norm": 5.000080108642578,
      "learning_rate": 0.00019911292256053704,
      "loss": 2.2226,
      "step": 22600
    },
    {
      "epoch": 1.8141133221449692,
      "grad_norm": 5.661811351776123,
      "learning_rate": 0.0001977809744532353,
      "loss": 2.1798,
      "step": 22700
    },
    {
      "epoch": 1.8221050107887797,
      "grad_norm": 4.323950290679932,
      "learning_rate": 0.00019644902634593356,
      "loss": 2.1636,
      "step": 22800
    },
    {
      "epoch": 1.8300966994325902,
      "grad_norm": 4.864846229553223,
      "learning_rate": 0.00019511707823863185,
      "loss": 2.2358,
      "step": 22900
    },
    {
      "epoch": 1.8380883880764005,
      "grad_norm": 4.483724117279053,
      "learning_rate": 0.00019378513013133008,
      "loss": 2.1859,
      "step": 23000
    },
    {
      "epoch": 1.846080076720211,
      "grad_norm": 6.146681308746338,
      "learning_rate": 0.00019245318202402835,
      "loss": 2.1972,
      "step": 23100
    },
    {
      "epoch": 1.8540717653640213,
      "grad_norm": 5.880358695983887,
      "learning_rate": 0.0001911212339167266,
      "loss": 2.2057,
      "step": 23200
    },
    {
      "epoch": 1.8620634540078318,
      "grad_norm": 5.413558006286621,
      "learning_rate": 0.00018978928580942487,
      "loss": 2.1867,
      "step": 23300
    },
    {
      "epoch": 1.8700551426516423,
      "grad_norm": 5.786203384399414,
      "learning_rate": 0.0001884573377021231,
      "loss": 2.1662,
      "step": 23400
    },
    {
      "epoch": 1.8780468312954528,
      "grad_norm": 6.485547065734863,
      "learning_rate": 0.0001871253895948214,
      "loss": 2.1721,
      "step": 23500
    },
    {
      "epoch": 1.8860385199392633,
      "grad_norm": 5.55372953414917,
      "learning_rate": 0.00018579344148751965,
      "loss": 2.159,
      "step": 23600
    },
    {
      "epoch": 1.8940302085830736,
      "grad_norm": 4.681952476501465,
      "learning_rate": 0.00018446149338021791,
      "loss": 2.1977,
      "step": 23700
    },
    {
      "epoch": 1.902021897226884,
      "grad_norm": 6.619851112365723,
      "learning_rate": 0.00018312954527291618,
      "loss": 2.1806,
      "step": 23800
    },
    {
      "epoch": 1.9100135858706944,
      "grad_norm": 5.820911884307861,
      "learning_rate": 0.0001817975971656144,
      "loss": 2.209,
      "step": 23900
    },
    {
      "epoch": 1.9180052745145049,
      "grad_norm": 5.077188491821289,
      "learning_rate": 0.0001804656490583127,
      "loss": 2.1802,
      "step": 24000
    },
    {
      "epoch": 1.9259969631583154,
      "grad_norm": 5.344286918640137,
      "learning_rate": 0.00017913370095101096,
      "loss": 2.1941,
      "step": 24100
    },
    {
      "epoch": 1.9339886518021259,
      "grad_norm": 3.7459120750427246,
      "learning_rate": 0.00017780175284370922,
      "loss": 2.2076,
      "step": 24200
    },
    {
      "epoch": 1.9419803404459364,
      "grad_norm": 5.105837345123291,
      "learning_rate": 0.0001764831242174805,
      "loss": 2.1782,
      "step": 24300
    },
    {
      "epoch": 1.9499720290897467,
      "grad_norm": 5.0781121253967285,
      "learning_rate": 0.00017515117611017876,
      "loss": 2.2192,
      "step": 24400
    },
    {
      "epoch": 1.9579637177335572,
      "grad_norm": 4.761772155761719,
      "learning_rate": 0.000173819228002877,
      "loss": 2.2179,
      "step": 24500
    },
    {
      "epoch": 1.9659554063773674,
      "grad_norm": 5.716140270233154,
      "learning_rate": 0.00017248727989557528,
      "loss": 2.2164,
      "step": 24600
    },
    {
      "epoch": 1.973947095021178,
      "grad_norm": 5.163365840911865,
      "learning_rate": 0.00017115533178827352,
      "loss": 2.1267,
      "step": 24700
    },
    {
      "epoch": 1.9819387836649884,
      "grad_norm": 5.197056770324707,
      "learning_rate": 0.0001698233836809718,
      "loss": 2.163,
      "step": 24800
    },
    {
      "epoch": 1.989930472308799,
      "grad_norm": 4.567313194274902,
      "learning_rate": 0.00016849143557367007,
      "loss": 2.2145,
      "step": 24900
    },
    {
      "epoch": 1.9979221609526094,
      "grad_norm": 6.164327621459961,
      "learning_rate": 0.0001671594874663683,
      "loss": 2.2101,
      "step": 25000
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.9804930686950684,
      "eval_runtime": 174.8271,
      "eval_samples_per_second": 286.289,
      "eval_steps_per_second": 17.898,
      "step": 25026
    },
    {
      "epoch": 2.00591384959642,
      "grad_norm": 4.986512660980225,
      "learning_rate": 0.0001658275393590666,
      "loss": 2.1674,
      "step": 25100
    },
    {
      "epoch": 2.01390553824023,
      "grad_norm": 4.670063018798828,
      "learning_rate": 0.00016449559125176482,
      "loss": 2.1813,
      "step": 25200
    },
    {
      "epoch": 2.0218972268840405,
      "grad_norm": 6.169525146484375,
      "learning_rate": 0.0001631636431444631,
      "loss": 2.1934,
      "step": 25300
    },
    {
      "epoch": 2.029888915527851,
      "grad_norm": 5.671971321105957,
      "learning_rate": 0.00016183169503716135,
      "loss": 2.1633,
      "step": 25400
    },
    {
      "epoch": 2.0378806041716615,
      "grad_norm": 6.124148368835449,
      "learning_rate": 0.0001604997469298596,
      "loss": 2.154,
      "step": 25500
    },
    {
      "epoch": 2.045872292815472,
      "grad_norm": 6.246192455291748,
      "learning_rate": 0.0001591677988225579,
      "loss": 2.1516,
      "step": 25600
    },
    {
      "epoch": 2.0538639814592825,
      "grad_norm": 6.866201400756836,
      "learning_rate": 0.00015783585071525613,
      "loss": 2.1772,
      "step": 25700
    },
    {
      "epoch": 2.0618556701030926,
      "grad_norm": 4.121890544891357,
      "learning_rate": 0.0001565039026079544,
      "loss": 2.1887,
      "step": 25800
    },
    {
      "epoch": 2.069847358746903,
      "grad_norm": 6.99081563949585,
      "learning_rate": 0.00015517195450065265,
      "loss": 2.2179,
      "step": 25900
    },
    {
      "epoch": 2.0778390473907136,
      "grad_norm": 5.478553771972656,
      "learning_rate": 0.00015384000639335091,
      "loss": 2.1992,
      "step": 26000
    },
    {
      "epoch": 2.085830736034524,
      "grad_norm": 5.196871757507324,
      "learning_rate": 0.0001525080582860492,
      "loss": 2.1063,
      "step": 26100
    },
    {
      "epoch": 2.0938224246783346,
      "grad_norm": 5.629741191864014,
      "learning_rate": 0.00015117611017874744,
      "loss": 2.1664,
      "step": 26200
    },
    {
      "epoch": 2.101814113322145,
      "grad_norm": 5.0685648918151855,
      "learning_rate": 0.0001498441620714457,
      "loss": 2.2165,
      "step": 26300
    },
    {
      "epoch": 2.1098058019659556,
      "grad_norm": 5.311417579650879,
      "learning_rate": 0.00014851221396414396,
      "loss": 2.2078,
      "step": 26400
    },
    {
      "epoch": 2.1177974906097656,
      "grad_norm": 4.987418174743652,
      "learning_rate": 0.00014718026585684222,
      "loss": 2.1519,
      "step": 26500
    },
    {
      "epoch": 2.125789179253576,
      "grad_norm": 5.332749366760254,
      "learning_rate": 0.00014584831774954048,
      "loss": 2.1411,
      "step": 26600
    },
    {
      "epoch": 2.1337808678973866,
      "grad_norm": 4.996980667114258,
      "learning_rate": 0.00014451636964223874,
      "loss": 2.2332,
      "step": 26700
    },
    {
      "epoch": 2.141772556541197,
      "grad_norm": 5.026033878326416,
      "learning_rate": 0.000143184421534937,
      "loss": 2.1399,
      "step": 26800
    },
    {
      "epoch": 2.1497642451850076,
      "grad_norm": 4.904752731323242,
      "learning_rate": 0.00014185247342763527,
      "loss": 2.2077,
      "step": 26900
    },
    {
      "epoch": 2.157755933828818,
      "grad_norm": 6.006564140319824,
      "learning_rate": 0.00014052052532033353,
      "loss": 2.204,
      "step": 27000
    },
    {
      "epoch": 2.1657476224726286,
      "grad_norm": 5.830959320068359,
      "learning_rate": 0.00013918857721303176,
      "loss": 2.1314,
      "step": 27100
    },
    {
      "epoch": 2.1737393111164387,
      "grad_norm": 5.049122333526611,
      "learning_rate": 0.00013785662910573005,
      "loss": 2.1972,
      "step": 27200
    },
    {
      "epoch": 2.181730999760249,
      "grad_norm": 5.636696815490723,
      "learning_rate": 0.00013652468099842829,
      "loss": 2.1656,
      "step": 27300
    },
    {
      "epoch": 2.1897226884040597,
      "grad_norm": 5.668638229370117,
      "learning_rate": 0.00013519273289112657,
      "loss": 2.2216,
      "step": 27400
    },
    {
      "epoch": 2.19771437704787,
      "grad_norm": 5.292688369750977,
      "learning_rate": 0.00013386078478382484,
      "loss": 2.1717,
      "step": 27500
    },
    {
      "epoch": 2.2057060656916807,
      "grad_norm": 5.813315391540527,
      "learning_rate": 0.00013252883667652307,
      "loss": 2.1503,
      "step": 27600
    },
    {
      "epoch": 2.213697754335491,
      "grad_norm": 5.186374187469482,
      "learning_rate": 0.00013119688856922136,
      "loss": 2.2345,
      "step": 27700
    },
    {
      "epoch": 2.2216894429793017,
      "grad_norm": 6.750067710876465,
      "learning_rate": 0.0001298649404619196,
      "loss": 2.1911,
      "step": 27800
    },
    {
      "epoch": 2.2296811316231118,
      "grad_norm": 8.279193878173828,
      "learning_rate": 0.00012854631183569087,
      "loss": 2.1737,
      "step": 27900
    },
    {
      "epoch": 2.2376728202669223,
      "grad_norm": 5.100640296936035,
      "learning_rate": 0.00012721436372838916,
      "loss": 2.2045,
      "step": 28000
    },
    {
      "epoch": 2.2456645089107328,
      "grad_norm": 5.058160781860352,
      "learning_rate": 0.00012588241562108742,
      "loss": 2.2013,
      "step": 28100
    },
    {
      "epoch": 2.2536561975545433,
      "grad_norm": 7.993875026702881,
      "learning_rate": 0.00012455046751378568,
      "loss": 2.1695,
      "step": 28200
    },
    {
      "epoch": 2.2616478861983538,
      "grad_norm": 6.925723552703857,
      "learning_rate": 0.00012321851940648394,
      "loss": 2.1847,
      "step": 28300
    },
    {
      "epoch": 2.2696395748421643,
      "grad_norm": 5.050206661224365,
      "learning_rate": 0.00012188657129918217,
      "loss": 2.1192,
      "step": 28400
    },
    {
      "epoch": 2.2776312634859748,
      "grad_norm": 5.1704301834106445,
      "learning_rate": 0.00012055462319188045,
      "loss": 2.2238,
      "step": 28500
    },
    {
      "epoch": 2.285622952129785,
      "grad_norm": 4.848993301391602,
      "learning_rate": 0.00011922267508457871,
      "loss": 2.1893,
      "step": 28600
    },
    {
      "epoch": 2.2936146407735953,
      "grad_norm": 5.802577495574951,
      "learning_rate": 0.00011789072697727697,
      "loss": 2.203,
      "step": 28700
    },
    {
      "epoch": 2.301606329417406,
      "grad_norm": 5.659438610076904,
      "learning_rate": 0.00011655877886997523,
      "loss": 2.238,
      "step": 28800
    },
    {
      "epoch": 2.3095980180612163,
      "grad_norm": 4.273326396942139,
      "learning_rate": 0.00011522683076267348,
      "loss": 2.1379,
      "step": 28900
    },
    {
      "epoch": 2.317589706705027,
      "grad_norm": 5.206600666046143,
      "learning_rate": 0.00011389488265537174,
      "loss": 2.1662,
      "step": 29000
    },
    {
      "epoch": 2.3255813953488373,
      "grad_norm": 4.801243305206299,
      "learning_rate": 0.00011256293454807002,
      "loss": 2.2636,
      "step": 29100
    },
    {
      "epoch": 2.333573083992648,
      "grad_norm": 6.292725086212158,
      "learning_rate": 0.00011123098644076828,
      "loss": 2.2302,
      "step": 29200
    },
    {
      "epoch": 2.341564772636458,
      "grad_norm": 4.680057525634766,
      "learning_rate": 0.00010989903833346653,
      "loss": 2.1796,
      "step": 29300
    },
    {
      "epoch": 2.3495564612802684,
      "grad_norm": 4.6389570236206055,
      "learning_rate": 0.00010856709022616479,
      "loss": 2.1721,
      "step": 29400
    },
    {
      "epoch": 2.357548149924079,
      "grad_norm": 5.721165657043457,
      "learning_rate": 0.00010723514211886305,
      "loss": 2.2493,
      "step": 29500
    },
    {
      "epoch": 2.3655398385678894,
      "grad_norm": 4.564913272857666,
      "learning_rate": 0.00010590319401156131,
      "loss": 2.1463,
      "step": 29600
    },
    {
      "epoch": 2.3735315272117,
      "grad_norm": 4.646454811096191,
      "learning_rate": 0.00010457124590425956,
      "loss": 2.2339,
      "step": 29700
    },
    {
      "epoch": 2.3815232158555104,
      "grad_norm": 6.121894359588623,
      "learning_rate": 0.00010323929779695783,
      "loss": 2.108,
      "step": 29800
    },
    {
      "epoch": 2.389514904499321,
      "grad_norm": 7.221587181091309,
      "learning_rate": 0.0001019073496896561,
      "loss": 2.2207,
      "step": 29900
    },
    {
      "epoch": 2.397506593143131,
      "grad_norm": 6.457777976989746,
      "learning_rate": 0.00010057540158235436,
      "loss": 2.2489,
      "step": 30000
    },
    {
      "epoch": 2.4054982817869415,
      "grad_norm": 5.646657943725586,
      "learning_rate": 9.924345347505262e-05,
      "loss": 2.2372,
      "step": 30100
    },
    {
      "epoch": 2.413489970430752,
      "grad_norm": 6.0178704261779785,
      "learning_rate": 9.791150536775087e-05,
      "loss": 2.1474,
      "step": 30200
    },
    {
      "epoch": 2.4214816590745625,
      "grad_norm": 7.220373630523682,
      "learning_rate": 9.657955726044913e-05,
      "loss": 2.1798,
      "step": 30300
    },
    {
      "epoch": 2.429473347718373,
      "grad_norm": 5.187565326690674,
      "learning_rate": 9.52476091531474e-05,
      "loss": 2.2407,
      "step": 30400
    },
    {
      "epoch": 2.4374650363621835,
      "grad_norm": 6.457372188568115,
      "learning_rate": 9.391566104584566e-05,
      "loss": 2.1915,
      "step": 30500
    },
    {
      "epoch": 2.445456725005994,
      "grad_norm": 5.265717029571533,
      "learning_rate": 9.258371293854391e-05,
      "loss": 2.1718,
      "step": 30600
    },
    {
      "epoch": 2.453448413649804,
      "grad_norm": 5.671113014221191,
      "learning_rate": 9.125176483124217e-05,
      "loss": 2.1861,
      "step": 30700
    },
    {
      "epoch": 2.4614401022936145,
      "grad_norm": 6.512973785400391,
      "learning_rate": 8.991981672394044e-05,
      "loss": 2.1664,
      "step": 30800
    },
    {
      "epoch": 2.469431790937425,
      "grad_norm": 6.343705654144287,
      "learning_rate": 8.85878686166387e-05,
      "loss": 2.1841,
      "step": 30900
    },
    {
      "epoch": 2.4774234795812355,
      "grad_norm": 6.649384498596191,
      "learning_rate": 8.725592050933696e-05,
      "loss": 2.1433,
      "step": 31000
    },
    {
      "epoch": 2.485415168225046,
      "grad_norm": 6.54374885559082,
      "learning_rate": 8.592397240203522e-05,
      "loss": 2.2235,
      "step": 31100
    },
    {
      "epoch": 2.4934068568688565,
      "grad_norm": 5.013640880584717,
      "learning_rate": 8.459202429473348e-05,
      "loss": 2.1208,
      "step": 31200
    },
    {
      "epoch": 2.501398545512667,
      "grad_norm": 5.196292400360107,
      "learning_rate": 8.327339566850476e-05,
      "loss": 2.153,
      "step": 31300
    },
    {
      "epoch": 2.509390234156477,
      "grad_norm": 4.047738552093506,
      "learning_rate": 8.194144756120302e-05,
      "loss": 2.1301,
      "step": 31400
    },
    {
      "epoch": 2.5173819228002876,
      "grad_norm": 4.518636226654053,
      "learning_rate": 8.060949945390128e-05,
      "loss": 2.215,
      "step": 31500
    },
    {
      "epoch": 2.525373611444098,
      "grad_norm": 6.290866851806641,
      "learning_rate": 7.927755134659954e-05,
      "loss": 2.1572,
      "step": 31600
    },
    {
      "epoch": 2.5333653000879086,
      "grad_norm": 4.0396857261657715,
      "learning_rate": 7.794560323929779e-05,
      "loss": 2.1172,
      "step": 31700
    },
    {
      "epoch": 2.541356988731719,
      "grad_norm": 5.697015762329102,
      "learning_rate": 7.661365513199606e-05,
      "loss": 2.1182,
      "step": 31800
    },
    {
      "epoch": 2.5493486773755296,
      "grad_norm": 5.121277332305908,
      "learning_rate": 7.528170702469432e-05,
      "loss": 2.1965,
      "step": 31900
    },
    {
      "epoch": 2.55734036601934,
      "grad_norm": 4.797724723815918,
      "learning_rate": 7.394975891739259e-05,
      "loss": 2.1629,
      "step": 32000
    },
    {
      "epoch": 2.56533205466315,
      "grad_norm": 6.540056228637695,
      "learning_rate": 7.261781081009083e-05,
      "loss": 2.237,
      "step": 32100
    },
    {
      "epoch": 2.5733237433069607,
      "grad_norm": 5.442212104797363,
      "learning_rate": 7.12858627027891e-05,
      "loss": 2.2069,
      "step": 32200
    },
    {
      "epoch": 2.581315431950771,
      "grad_norm": 5.604047775268555,
      "learning_rate": 6.995391459548736e-05,
      "loss": 2.1757,
      "step": 32300
    },
    {
      "epoch": 2.5893071205945817,
      "grad_norm": 4.798964023590088,
      "learning_rate": 6.862196648818563e-05,
      "loss": 2.2121,
      "step": 32400
    },
    {
      "epoch": 2.597298809238392,
      "grad_norm": 4.959336757659912,
      "learning_rate": 6.729001838088389e-05,
      "loss": 2.1439,
      "step": 32500
    },
    {
      "epoch": 2.6052904978822022,
      "grad_norm": 4.527223587036133,
      "learning_rate": 6.595807027358214e-05,
      "loss": 2.2246,
      "step": 32600
    },
    {
      "epoch": 2.613282186526013,
      "grad_norm": 5.89091682434082,
      "learning_rate": 6.46261221662804e-05,
      "loss": 2.1455,
      "step": 32700
    },
    {
      "epoch": 2.6212738751698232,
      "grad_norm": 4.779417991638184,
      "learning_rate": 6.329417405897866e-05,
      "loss": 2.2086,
      "step": 32800
    },
    {
      "epoch": 2.6292655638136337,
      "grad_norm": 4.989590644836426,
      "learning_rate": 6.196222595167693e-05,
      "loss": 2.1314,
      "step": 32900
    },
    {
      "epoch": 2.6372572524574442,
      "grad_norm": 6.199790000915527,
      "learning_rate": 6.0630277844375187e-05,
      "loss": 2.1811,
      "step": 33000
    },
    {
      "epoch": 2.6452489411012547,
      "grad_norm": 7.134167671203613,
      "learning_rate": 5.929832973707344e-05,
      "loss": 2.1929,
      "step": 33100
    },
    {
      "epoch": 2.6532406297450652,
      "grad_norm": 7.495222091674805,
      "learning_rate": 5.79663816297717e-05,
      "loss": 2.1499,
      "step": 33200
    },
    {
      "epoch": 2.6612323183888753,
      "grad_norm": 7.308454990386963,
      "learning_rate": 5.663443352246997e-05,
      "loss": 2.151,
      "step": 33300
    },
    {
      "epoch": 2.6692240070326863,
      "grad_norm": 4.728734493255615,
      "learning_rate": 5.5302485415168225e-05,
      "loss": 2.1852,
      "step": 33400
    },
    {
      "epoch": 2.6772156956764963,
      "grad_norm": 4.620800495147705,
      "learning_rate": 5.397053730786649e-05,
      "loss": 2.2571,
      "step": 33500
    },
    {
      "epoch": 2.685207384320307,
      "grad_norm": 4.3527302742004395,
      "learning_rate": 5.263858920056475e-05,
      "loss": 2.1888,
      "step": 33600
    },
    {
      "epoch": 2.6931990729641173,
      "grad_norm": 6.461121559143066,
      "learning_rate": 5.130664109326301e-05,
      "loss": 2.183,
      "step": 33700
    },
    {
      "epoch": 2.701190761607928,
      "grad_norm": 4.830435276031494,
      "learning_rate": 4.9974692985961264e-05,
      "loss": 2.2055,
      "step": 33800
    },
    {
      "epoch": 2.7091824502517383,
      "grad_norm": 4.610945701599121,
      "learning_rate": 4.864274487865953e-05,
      "loss": 2.1307,
      "step": 33900
    },
    {
      "epoch": 2.7171741388955484,
      "grad_norm": 5.384176254272461,
      "learning_rate": 4.731079677135779e-05,
      "loss": 2.2249,
      "step": 34000
    },
    {
      "epoch": 2.7251658275393593,
      "grad_norm": 6.558887481689453,
      "learning_rate": 4.597884866405605e-05,
      "loss": 2.1024,
      "step": 34100
    },
    {
      "epoch": 2.7331575161831694,
      "grad_norm": 6.0827789306640625,
      "learning_rate": 4.46469005567543e-05,
      "loss": 2.1202,
      "step": 34200
    },
    {
      "epoch": 2.74114920482698,
      "grad_norm": 5.580050468444824,
      "learning_rate": 4.331495244945257e-05,
      "loss": 2.1485,
      "step": 34300
    },
    {
      "epoch": 2.7491408934707904,
      "grad_norm": 4.741929054260254,
      "learning_rate": 4.198300434215083e-05,
      "loss": 2.1395,
      "step": 34400
    },
    {
      "epoch": 2.757132582114601,
      "grad_norm": 6.394212245941162,
      "learning_rate": 4.065105623484909e-05,
      "loss": 2.1366,
      "step": 34500
    },
    {
      "epoch": 2.7651242707584114,
      "grad_norm": 7.056485652923584,
      "learning_rate": 3.9319108127547356e-05,
      "loss": 2.209,
      "step": 34600
    },
    {
      "epoch": 2.7731159594022214,
      "grad_norm": 5.304403305053711,
      "learning_rate": 3.798716002024561e-05,
      "loss": 2.1548,
      "step": 34700
    },
    {
      "epoch": 2.7811076480460324,
      "grad_norm": 4.774303913116455,
      "learning_rate": 3.665521191294387e-05,
      "loss": 2.1298,
      "step": 34800
    },
    {
      "epoch": 2.7890993366898424,
      "grad_norm": 6.928602695465088,
      "learning_rate": 3.532326380564213e-05,
      "loss": 2.205,
      "step": 34900
    },
    {
      "epoch": 2.797091025333653,
      "grad_norm": 5.438051700592041,
      "learning_rate": 3.3991315698340395e-05,
      "loss": 2.1768,
      "step": 35000
    },
    {
      "epoch": 2.8050827139774634,
      "grad_norm": 6.035121917724609,
      "learning_rate": 3.265936759103865e-05,
      "loss": 2.1481,
      "step": 35100
    },
    {
      "epoch": 2.813074402621274,
      "grad_norm": 4.503566741943359,
      "learning_rate": 3.132741948373692e-05,
      "loss": 2.1778,
      "step": 35200
    },
    {
      "epoch": 2.8210660912650845,
      "grad_norm": 4.888858318328857,
      "learning_rate": 2.9995471376435176e-05,
      "loss": 2.1201,
      "step": 35300
    },
    {
      "epoch": 2.8290577799088945,
      "grad_norm": 4.420898914337158,
      "learning_rate": 2.8676842750206454e-05,
      "loss": 2.205,
      "step": 35400
    },
    {
      "epoch": 2.8370494685527055,
      "grad_norm": 4.685615062713623,
      "learning_rate": 2.7344894642904715e-05,
      "loss": 2.1677,
      "step": 35500
    },
    {
      "epoch": 2.8450411571965155,
      "grad_norm": 4.8848443031311035,
      "learning_rate": 2.6012946535602973e-05,
      "loss": 2.1375,
      "step": 35600
    },
    {
      "epoch": 2.853032845840326,
      "grad_norm": 4.122997283935547,
      "learning_rate": 2.4680998428301235e-05,
      "loss": 2.1653,
      "step": 35700
    },
    {
      "epoch": 2.8610245344841365,
      "grad_norm": 5.131232261657715,
      "learning_rate": 2.3349050320999493e-05,
      "loss": 2.2339,
      "step": 35800
    },
    {
      "epoch": 2.869016223127947,
      "grad_norm": 4.769345283508301,
      "learning_rate": 2.2017102213697754e-05,
      "loss": 2.2193,
      "step": 35900
    },
    {
      "epoch": 2.8770079117717575,
      "grad_norm": 4.332467555999756,
      "learning_rate": 2.0685154106396016e-05,
      "loss": 2.1472,
      "step": 36000
    },
    {
      "epoch": 2.8849996004155676,
      "grad_norm": 4.130829811096191,
      "learning_rate": 1.9353205999094274e-05,
      "loss": 2.1542,
      "step": 36100
    },
    {
      "epoch": 2.8929912890593785,
      "grad_norm": 4.819817066192627,
      "learning_rate": 1.8021257891792535e-05,
      "loss": 2.1561,
      "step": 36200
    },
    {
      "epoch": 2.9009829777031886,
      "grad_norm": 5.572491645812988,
      "learning_rate": 1.6689309784490797e-05,
      "loss": 2.1756,
      "step": 36300
    },
    {
      "epoch": 2.908974666346999,
      "grad_norm": 4.069593906402588,
      "learning_rate": 1.5357361677189058e-05,
      "loss": 2.1493,
      "step": 36400
    },
    {
      "epoch": 2.9169663549908096,
      "grad_norm": 4.728322982788086,
      "learning_rate": 1.4025413569887316e-05,
      "loss": 2.1447,
      "step": 36500
    },
    {
      "epoch": 2.92495804363462,
      "grad_norm": 4.957803249359131,
      "learning_rate": 1.269346546258558e-05,
      "loss": 2.1859,
      "step": 36600
    },
    {
      "epoch": 2.9329497322784306,
      "grad_norm": 5.285063743591309,
      "learning_rate": 1.1361517355283839e-05,
      "loss": 2.1998,
      "step": 36700
    },
    {
      "epoch": 2.9409414209222406,
      "grad_norm": 6.594818115234375,
      "learning_rate": 1.0029569247982099e-05,
      "loss": 2.2359,
      "step": 36800
    },
    {
      "epoch": 2.948933109566051,
      "grad_norm": 6.442505836486816,
      "learning_rate": 8.697621140680358e-06,
      "loss": 2.2234,
      "step": 36900
    },
    {
      "epoch": 2.9569247982098616,
      "grad_norm": 4.623482704162598,
      "learning_rate": 7.36567303337862e-06,
      "loss": 2.1178,
      "step": 37000
    },
    {
      "epoch": 2.964916486853672,
      "grad_norm": 7.649477958679199,
      "learning_rate": 6.0337249260768805e-06,
      "loss": 2.1874,
      "step": 37100
    },
    {
      "epoch": 2.9729081754974827,
      "grad_norm": 5.079281330108643,
      "learning_rate": 4.70177681877514e-06,
      "loss": 2.1772,
      "step": 37200
    },
    {
      "epoch": 2.980899864141293,
      "grad_norm": 4.783857822418213,
      "learning_rate": 3.369828711473401e-06,
      "loss": 2.1588,
      "step": 37300
    },
    {
      "epoch": 2.9888915527851037,
      "grad_norm": 5.304446697235107,
      "learning_rate": 2.051200085244679e-06,
      "loss": 2.0988,
      "step": 37400
    },
    {
      "epoch": 2.9968832414289137,
      "grad_norm": 5.304930210113525,
      "learning_rate": 7.192519779429394e-07,
      "loss": 2.0759,
      "step": 37500
    }
  ],
  "logging_steps": 100,
  "max_steps": 37539,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.962465825826816e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
